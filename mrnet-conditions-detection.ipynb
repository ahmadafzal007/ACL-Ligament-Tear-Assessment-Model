{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66baa804",
   "metadata": {
    "papermill": {
     "duration": 0.030245,
     "end_time": "2024-08-09T16:21:53.037246",
     "exception": false,
     "start_time": "2024-08-09T16:21:53.007001",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing of MRNet and Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28e3ba66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-09T16:21:53.099637Z",
     "iopub.status.busy": "2024-08-09T16:21:53.099212Z",
     "iopub.status.idle": "2024-08-09T16:21:55.363449Z",
     "shell.execute_reply": "2024-08-09T16:21:55.361930Z"
    },
    "papermill": {
     "duration": 2.29808,
     "end_time": "2024-08-09T16:21:55.365364",
     "exception": true,
     "start_time": "2024-08-09T16:21:53.067284",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "from glob import glob\n",
    "from scipy import ndimage\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65512218",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mrnet_dataset_dir = 'Data/MRNet-v1.0'\n",
    "mrnet_train_path = os.path.join(mrnet_dataset_dir, 'train')\n",
    "mrnet_valid_path = os.path.join(mrnet_dataset_dir, 'valid')\n",
    "mrnet_planes = ['axial', 'coronal', 'sagittal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a24c00",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For running code on Windows\n",
    "if platform.system() == \"Windows\":\n",
    "    mrnet_dataset_dir = mrnet_dataset_dir.replace('/', '\\\\')\n",
    "    mrnet_train_path = mrnet_train_path.replace('/', '\\\\')\n",
    "    mrnet_valid_path = mrnet_valid_path.replace('/', '\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb30bc0b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mrnet_datasets = {'train': mrnet_train_path, 'valid': mrnet_valid_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d02c92",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mrnet_labels = ['abnormal', 'acl', 'meniscus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ec4860",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TRAIN DATASET\n",
    "for label in mrnet_labels:\n",
    "    if platform.system() == \"Windows\":\n",
    "        if label == 'abnormal':\n",
    "            train_abnormal_df = pd.read_csv(f\"{mrnet_dataset_dir}\\\\train-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case', 'Abnormal'],\n",
    "                                            dtype={'Case': str, 'Abnormal': np.int64})\n",
    "        elif label == 'acl':\n",
    "            train_acl_df = pd.read_csv(f\"{mrnet_dataset_dir}\\\\train-{label}.csv\",\n",
    "                                       header=None,\n",
    "                                       names=['Case', 'ACL'],\n",
    "                                       dtype={'Case': str, 'ACL': np.int64})\n",
    "        if label == 'meniscus':\n",
    "            train_meniscus_df = pd.read_csv(f\"{mrnet_dataset_dir}\\\\train-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case', 'Meniscus'],\n",
    "                                            dtype={'Case': str, 'Meniscus': np.int64})\n",
    "    else:\n",
    "        if label == 'abnormal':\n",
    "            train_abnormal_df = pd.read_csv(f\"{mrnet_dataset_dir}/train-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case', 'Abnormal'],\n",
    "                                            dtype={'Case': str, 'Abnormal': np.int64})\n",
    "        elif label == 'acl':\n",
    "            train_acl_df = pd.read_csv(f\"{mrnet_dataset_dir}/train-{label}.csv\",\n",
    "                                       header=None,\n",
    "                                       names=['Case', 'ACL'],\n",
    "                                       dtype={'Case': str, 'ACL': np.int64})\n",
    "        if label == 'meniscus':\n",
    "            train_meniscus_df = pd.read_csv(f\"{mrnet_dataset_dir}/train-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case', 'Meniscus'],\n",
    "                                            dtype={'Case': str, 'Meniscus': np.int64})\n",
    "\n",
    "train_df = pd.merge(train_abnormal_df, train_acl_df, on='Case').merge(train_meniscus_df, on='Case')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61e20e8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# VALID DATASET\n",
    "for label in mrnet_labels:\n",
    "    if platform.system() == \"Windows\":\n",
    "        if label == 'abnormal':\n",
    "            valid_abnormal_df = pd.read_csv(f\"{mrnet_dataset_dir}\\\\valid-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case', 'Abnormal'],\n",
    "                                            dtype={'Case': str, 'Abnormal': np.int64})\n",
    "        elif label == 'acl':\n",
    "            valid_acl_df = pd.read_csv(f\"{mrnet_dataset_dir}\\\\valid-{label}.csv\",\n",
    "                                       header=None,\n",
    "                                       names=['Case', 'ACL'],\n",
    "                                       dtype={'Case': str, 'ACL': np.int64})\n",
    "        if label == 'meniscus':\n",
    "            valid_meniscus_df = pd.read_csv(f\"{mrnet_dataset_dir}\\\\valid-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case', 'Meniscus'],\n",
    "                                            dtype={'Case': str, 'Meniscus': np.int64})\n",
    "    else:\n",
    "        if label == 'abnormal':\n",
    "            valid_abnormal_df = pd.read_csv(f\"{mrnet_dataset_dir}/valid-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case', 'Abnormal'],\n",
    "                                            dtype={'Case': str, 'Abnormal': np.int64})\n",
    "        elif label == 'acl':\n",
    "            valid_acl_df = pd.read_csv(f\"{mrnet_dataset_dir}/valid-{label}.csv\",\n",
    "                                       header=None,\n",
    "                                       names=['Case', 'ACL'],\n",
    "                                       dtype={'Case': str, 'ACL': np.int64})\n",
    "        if label == 'meniscus':\n",
    "            valid_meniscus_df = pd.read_csv(f\"{mrnet_dataset_dir}/valid-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case', 'Meniscus'],\n",
    "                                            dtype={'Case': str, 'Meniscus': np.int64})\n",
    "\n",
    "valid_df = pd.merge(valid_abnormal_df, valid_acl_df, on='Case').merge(valid_meniscus_df, on='Case')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80f6284",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def resize_3D_volume(vol, target_size=(30, 256, 256)):\n",
    "    \"\"\"\n",
    "    Given a 3D volumteric array with shape (Z,X,Y). This function will resize\n",
    "    the image across z-axis.\n",
    "    The purpose of this function to standardise the depth of MRI image.\n",
    "\n",
    "    Args:\n",
    "        vol: 3D array with shape (Z,X,Y) that represents the volume of a MRI image\n",
    "        target_size: target size to shape into the volumetric data\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Returns the resized MRI volume\n",
    "    \"\"\"\n",
    "    # Set the desired depth\n",
    "    desired_depth, desired_width, desired_height = target_size\n",
    "    # Get current depth\n",
    "    current_depth = vol.shape[0]\n",
    "    current_width = vol.shape[1]\n",
    "    current_height = vol.shape[2]\n",
    "    # Compute depth factor\n",
    "    depth = current_depth / desired_depth\n",
    "    width = current_width / desired_width\n",
    "    height = current_height / desired_height\n",
    "    depth_factor = 1 / depth\n",
    "    width_factor = 1 / width\n",
    "    height_factor = 1 / height\n",
    "    # Resize across z-axis\n",
    "    resized_vol = ndimage.zoom(vol, (depth_factor, width_factor, height_factor), order=1)\n",
    "    return resized_vol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e6d055",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def denoise_3D_volume(vol):\n",
    "    \"\"\"Summary\n",
    "\n",
    "    Args:\n",
    "        vol (np.ndarray): MRI volume to denoise\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Returns denoised MRI volume\n",
    "    \"\"\"\n",
    "    vol_sitk = sitk.GetImageFromArray(vol)\n",
    "    denoised_vol_sitk = sitk.CurvatureFlow(vol_sitk, timeStep=0.01, numberOfIterations=7)\n",
    "    denoised_vol = sitk.GetArrayFromImage(denoised_vol_sitk)\n",
    "    return denoised_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f083ae9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def efficient_bias_field_correction_volume(vol):\n",
    "    \"\"\"Summary\n",
    "\n",
    "    Args:\n",
    "        vol (np.ndarray): MRI volume to perform efficient bias field correction\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Returns bias field corrected MRI volume\n",
    "    \"\"\"\n",
    "    # Ref: https://medium.com/@alexandro.ramr777/how-to-do-bias-field-correction-with-python-156b9d51dd79\n",
    "    # Ref: https://simpleitk.readthedocs.io/en/master/link_N4BiasFieldCorrection_docs.html\n",
    "    # Convert the NumPy array to SimpleITK image\n",
    "    vol_sitk = sitk.GetImageFromArray(vol)\n",
    "\n",
    "    vol_sitk = sitk.Cast(vol_sitk, sitk.sitkFloat64)\n",
    "\n",
    "    vol_sitk_transformed = sitk.RescaleIntensity(vol_sitk, 0, 255)\n",
    "\n",
    "    vol_sitk_transformed = sitk.LiThreshold(vol_sitk_transformed, 0, 1)\n",
    "\n",
    "    head_mask = vol_sitk_transformed\n",
    "\n",
    "    shrink_factor = 4\n",
    "\n",
    "    input_img = vol_sitk\n",
    "\n",
    "    input_img = sitk.Shrink(vol_sitk, [shrink_factor] * input_img.GetDimension())\n",
    "    mask_img = sitk.Shrink(head_mask, [shrink_factor] * input_img.GetDimension())\n",
    "\n",
    "    # Perform bias field correction using N4BiasFieldCorrection\n",
    "    bias_corrector = sitk.N4BiasFieldCorrectionImageFilter()\n",
    "    corrected = bias_corrector.Execute(input_img, mask_img)\n",
    "\n",
    "    log_bias_field = bias_corrector.GetLogBiasFieldAsImage(vol_sitk)\n",
    "\n",
    "    log_bias_field = sitk.Cast(log_bias_field, sitk.sitkFloat64)\n",
    "\n",
    "    corrected_image_full_resolution = vol_sitk / sitk.Exp(log_bias_field)\n",
    "\n",
    "    # Get the NumPy array representation of the bias-corrected volume\n",
    "    bias_corrected_vol = sitk.GetArrayFromImage(corrected_image_full_resolution)\n",
    "\n",
    "    return bias_corrected_vol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd55c3cc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalise_volume_pixels(vol):\n",
    "    \"\"\"Summary\n",
    "\n",
    "    Args:\n",
    "        vol (np.ndarray): MRI volume\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Normalised MRI volume\n",
    "    \"\"\"\n",
    "    # Normalise the volume pixels to the range [0, 1]\n",
    "    min_value = np.min(vol)\n",
    "    max_value = np.max(vol)\n",
    "    normalised_vol = (vol - min_value) / (max_value - min_value)\n",
    "\n",
    "    return normalised_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616d4c30",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def center_volume_pixels(vol):\n",
    "    \"\"\"Summary\n",
    "\n",
    "    Args:\n",
    "        vol (np.ndarray): MRI volume\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Zero centered MRI volume\n",
    "    \"\"\"\n",
    "    # Calculate the mean value\n",
    "    mean_value = np.mean(vol)\n",
    "\n",
    "    # Center the data\n",
    "    centered_vol = vol - mean_value\n",
    "\n",
    "    return centered_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c700cc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def standardise_volume_pixels(vol):\n",
    "    \"\"\"Summary\n",
    "\n",
    "    Args:\n",
    "        vol (np.ndarray): MRI volume\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Standardised MRI volume\n",
    "    \"\"\"\n",
    "    # Calculate the mean and standard deviation\n",
    "    mean_value = np.mean(vol)\n",
    "    std_value = np.std(vol)\n",
    "\n",
    "    # Standardise the data\n",
    "    standardised_vol = (vol - mean_value) / std_value\n",
    "\n",
    "    return standardised_vol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8a5a52",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_mri(mri_vol):\n",
    "    \"\"\"Summary\n",
    "\n",
    "    Args:\n",
    "        mri_vol (np.ndarray): MRI volume\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Returns preprocessed MRI volume\n",
    "    \"\"\"\n",
    "    mri_vol = resize_3D_volume(mri_vol)\n",
    "    mri_vol = denoise_3D_volume(mri_vol)\n",
    "    mri_vol = efficient_bias_field_correction_volume(mri_vol)\n",
    "    mri_vol = normalise_volume_pixels(mri_vol)\n",
    "    mri_vol = center_volume_pixels(mri_vol)\n",
    "    mri_vol = standardise_volume_pixels(mri_vol)\n",
    "    return mri_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee46478f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_mri_vols(cases, overwrite=False):\n",
    "    \"\"\"\n",
    "    This function preprocesses all the MRI volumes in MRNet\n",
    "    and stores them under 'Preprocessed_Data' directory.\n",
    "\n",
    "    Args:\n",
    "        cases (list): List of files in MRNet dataset\n",
    "        overwrite (bool, optional): Option to overwrite already preprocessed MRI\n",
    "    \"\"\"\n",
    "    cases.sort()\n",
    "    for case in cases:\n",
    "        mri_vol = np.load(case)\n",
    "        mri_vol = mri_vol.astype(np.float64)  # Change the dtype to float64\n",
    "\n",
    "        case_path = os.path.normpath(case).split(os.sep)\n",
    "        case_path[0] = 'Preprocessed_Data'\n",
    "        preprocessed_case_path = os.path.join(*case_path)\n",
    "\n",
    "        if overwrite or not os.path.exists(preprocessed_case_path):\n",
    "            preprocessed_mri_vol = preprocess_mri(mri_vol)\n",
    "            os.makedirs(os.path.join(*case_path[:-1]), exist_ok=True)\n",
    "            np.save(preprocessed_case_path, preprocessed_mri_vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e901a9a4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def random_horizontal_flip(vol):\n",
    "    \"\"\"Summary\n",
    "\n",
    "    Args:\n",
    "        vol (np.ndarray): MRI volume\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Returns horizontally flipped MRI volume\n",
    "    \"\"\"\n",
    "    flipped_vol = np.flip(vol, axis=2)\n",
    "    return flipped_vol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44ceaea",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def random_rotation(vol, rotation_angles=[-2.0, -1.5, -1.0, 1.0, 1.5, 2.0, ]):\n",
    "    \"\"\"Summary\n",
    "\n",
    "    Args:\n",
    "        vol (np.ndarray): MRI volume\n",
    "        rotation_angles (list, optional): List angles for random rotations\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Returns randomly rotated MRI volume\n",
    "    \"\"\"\n",
    "    rotation_angle = np.random.choice(rotation_angles)\n",
    "    # print(f\"Rotation by {rotation_angle} degrees.\")\n",
    "    rotated_vol = ndimage.rotate(vol, rotation_angle, reshape=False, mode='nearest')\n",
    "    # print(rotated_vol.shape)\n",
    "    return rotated_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8280531",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def augment_mri_vols(dataset, labels, aug_flip_prob=0.95, overwrite=False):\n",
    "    \"\"\"\n",
    "    This function augments MRI volumes in MRNet dataset to create more samples\n",
    "    for labels that have lower number of cases.\n",
    "\n",
    "    Args:\n",
    "        dataset (str): Path to either train or valid MRNet dataset\n",
    "        labels (Pandas dataframe): Labels dataframe for the exams\n",
    "        aug_flip_prob (float, optional): Augmentation flip probability\n",
    "        overwrite (bool, optional): Option to overwrite already preprocessed MRI\n",
    "    \"\"\"\n",
    "    aug_labels_list = []\n",
    "    plane = 'sagittal'\n",
    "    if platform.system() == \"Windows\":\n",
    "        cases = glob(f\"{dataset}\\\\{plane}\\\\*.npy\")\n",
    "    else:\n",
    "        cases = glob(f\"{dataset}/{plane}/*.npy\")\n",
    "    cases.sort()\n",
    "    for case in cases:\n",
    "        # We will create a new path file for augmented images by adding '_aug' in file names\n",
    "        # and we store them under the folder <plane>/aug\n",
    "\n",
    "        case_path = os.path.normpath(case).split(os.sep)\n",
    "        file_name = case_path[-1]\n",
    "\n",
    "        orig_sagittal = os.path.join(*case_path)\n",
    "\n",
    "        case_path[0] = 'Preprocessed_Data'\n",
    "        case_path.insert(-1, 'aug')\n",
    "\n",
    "        # SAGITTAL\n",
    "        sa_temp = file_name\n",
    "        dot_index = sa_temp.index('.')\n",
    "\n",
    "        # Do this only once as the label of augmented MRIs will be the same for all three planes and tasks\n",
    "        temp_aug_labels = labels.loc[labels['Case'] == sa_temp[:dot_index]][['Abnormal', 'ACL', 'Meniscus']].values.tolist()[0]\n",
    "\n",
    "        # If acl_diagnosis is 1, only 5% chance of augmentation as majority samples are without tear\n",
    "        # Increase probability of augmentation in case of ACL tears\n",
    "        if np.random.rand() >= aug_flip_prob or temp_aug_labels[1] == 1:\n",
    "\n",
    "            case_path[-1] = f\"{sa_temp[:dot_index]}-aug-0{sa_temp[dot_index:]}\"\n",
    "            aug_sagittal = os.path.join(*case_path)\n",
    "\n",
    "            if temp_aug_labels[1] == 0:\n",
    "                if overwrite or not os.path.exists(aug_sagittal):\n",
    "                    mri_vol = np.load(orig_sagittal)\n",
    "                    mri_vol = mri_vol.astype(np.float64)  # Change the dtype to float64\n",
    "\n",
    "                    aug_mri_vol = random_horizontal_flip(mri_vol)\n",
    "                    aug_mri_vol = random_rotation(aug_mri_vol)\n",
    "\n",
    "                    preprocessed_aug_mri_vol = preprocess_mri(aug_mri_vol)\n",
    "                    os.makedirs(os.path.join(*case_path[:-1]), exist_ok=True)\n",
    "                    np.save(aug_sagittal, preprocessed_aug_mri_vol)\n",
    "                    aug_labels_list.append([f\"{sa_temp[:dot_index]}-aug-0\"] + temp_aug_labels)\n",
    "\n",
    "            elif temp_aug_labels[1] == 1:\n",
    "                for aug_ind in range(3):  # We will augment sample three times\n",
    "                    if aug_ind >= 1:\n",
    "                        case_path[-1] = f\"{sa_temp[:dot_index]}-aug-{aug_ind}{sa_temp[dot_index:]}\"\n",
    "                        aug_sagittal = os.path.join(*case_path)\n",
    "\n",
    "                    if overwrite or not os.path.exists(aug_sagittal):\n",
    "                        mri_vol = np.load(orig_sagittal)\n",
    "                        mri_vol = mri_vol.astype(np.float64)  # Change the dtype to float64\n",
    "\n",
    "                        if aug_ind == 0:\n",
    "                            aug_mri_vol = random_horizontal_flip(mri_vol)\n",
    "                        elif aug_ind == 1:\n",
    "                            aug_mri_vol = random_rotation(mri_vol)\n",
    "                        elif aug_ind == 2:\n",
    "                            aug_mri_vol = random_horizontal_flip(mri_vol)\n",
    "                            aug_mri_vol = random_rotation(aug_mri_vol)\n",
    "                        preprocessed_aug_mri_vol = preprocess_mri(aug_mri_vol)\n",
    "                        os.makedirs(os.path.join(*case_path[:-1]), exist_ok=True)\n",
    "                        np.save(aug_sagittal, preprocessed_aug_mri_vol)\n",
    "                        aug_labels_list.append([f\"{sa_temp[:dot_index]}-aug-{aug_ind}\"] + temp_aug_labels)\n",
    "\n",
    "    aug_train_df = pd.DataFrame(aug_labels_list, columns=labels.columns)\n",
    "    # print(aug_train_df)\n",
    "    csv_file_path = os.path.normpath(dataset).split(os.sep)\n",
    "    if csv_file_path[-1] == 'train':\n",
    "        if platform.system() == \"Windows\":\n",
    "            aug_train_df.to_csv(os.path.join(*csv_file_path[:-1]) + \"\\\\train-aug.csv\")\n",
    "        else:\n",
    "            aug_train_df.to_csv(os.path.join(*csv_file_path[:-1]) + \"/train-aug.csv\")\n",
    "    elif csv_file_path[-1] == 'valid':\n",
    "        if platform.system() == \"Windows\":\n",
    "            aug_train_df.to_csv(os.path.join(*csv_file_path[:-1]) + \"\\\\valid-aug.csv\")\n",
    "        else:\n",
    "            aug_train_df.to_csv(os.path.join(*csv_file_path[:-1]) + \"/valid-aug.csv\")\n",
    "    print(f\"For {dataset.upper()} datset we have {len(aug_labels_list)} augmented samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6cb37a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_mri_vols_for_plane(dataset, plane):\n",
    "    \"\"\"\n",
    "    This function calls preprocessing on given dataset of MRNet\n",
    "    and plane.\n",
    "\n",
    "    Args:\n",
    "        dataset (str): Path to either train or valid MRNet dataset\n",
    "        plane (str): MRNet dataset plane axial, coronal or sagittal\n",
    "    \"\"\"\n",
    "    if platform.system() == \"Windows\":\n",
    "        cases = glob(f\"{dataset}\\\\{plane}\\\\*.npy\")\n",
    "    else:\n",
    "        cases = glob(f\"{dataset}/{plane}/*.npy\")\n",
    "    preprocess_mri_vols(cases)\n",
    "    print(f\"For {dataset.upper()} {plane} plane we have {len(cases)} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bd5025",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocess only sagittal plane\n",
    "preprocess_mri_vols_for_plane(mrnet_datasets['train'], 'sagittal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0d081f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocess only sagittal plane\n",
    "preprocess_mri_vols_for_plane(mrnet_datasets['valid'], 'sagittal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190b3c30",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "augment_mri_vols(mrnet_datasets['train'], train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540e08c7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "augment_mri_vols(mrnet_datasets['valid'], valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be97a4d2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083ddfd1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "827132a6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## MRNet Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b827280",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a47ca6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = 'Data/MRNet-v1.0'\n",
    "train_data_path = os.path.join(data_dir, 'train')\n",
    "valid_data_path = os.path.join(data_dir, 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c0dcee",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for dataset, path in datasets.items():\n",
    "    print(f\"\\nTotal exams in {dataset.upper()}\")\n",
    "    for plane in planes:\n",
    "        print(f\"{plane:8} plane : {len(glob(f'{os.path.join(path, plane)}/*.npy'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498d5337",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_slices_per_exam(exams):\n",
    "    \"\"\"\n",
    "    This function gets number of slices found in MRIs\n",
    "    of the MRNet dataset.\n",
    "\n",
    "    Args:\n",
    "        exams (list): List of files in MRNet dataset\n",
    "\n",
    "    Returns:\n",
    "        NumPy array: Array of slices per exam\n",
    "    \"\"\"\n",
    "    num_slices_per_exam = []\n",
    "    for exam in exams:\n",
    "        mri_vol = np.load(exam)\n",
    "        num_slices_per_exam.append(mri_vol.shape[0])\n",
    "    return np.asarray(num_slices_per_exam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d3d888",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_slices_per_exam(dataset):\n",
    "    \"\"\"\n",
    "    This function plots the distibution of slices found in MRIs\n",
    "    of the MRNet dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset (str): Path to either train or valid MRNet dataset\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "    for i, plane in enumerate(planes):\n",
    "        num_slices = get_slices_per_exam(glob(f\"{dataset}/{plane}/*.npy\"))\n",
    "        print(f\"For {dataset.upper()} {plane} plane min : {num_slices.min()}, max : {num_slices.max()}, avg : {num_slices.mean()}\")\n",
    "        sns.histplot(num_slices, stat='density', ax=axes[i], kde=True)\n",
    "        axes[i].set_title(f\"{plane.title()} Plane\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e838620a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TRAIN DATASET\n",
    "plot_slices_per_exam(datasets['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71991fa",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# VALID DATASET\n",
    "plot_slices_per_exam(datasets['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da85683",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TRAIN DATASET\n",
    "label_categories = ['abnormal', 'acl', 'meniscus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c510d0bd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for label in label_categories:\n",
    "    if label == 'abnormal':\n",
    "        train_abnormal_df = pd.read_csv(f\"{data_dir}/train-{label}.csv\",\n",
    "                                        header=None,\n",
    "                                        names=['Case', 'Abnormal'],\n",
    "                                        dtype={'Case': str, 'Abnormal': np.int64})\n",
    "    elif label == 'acl':\n",
    "        train_acl_df = pd.read_csv(f\"{data_dir}/train-{label}.csv\",\n",
    "                                   header=None,\n",
    "                                   names=['Case', 'ACL'],\n",
    "                                   dtype={'Case': str, 'ACL': np.int64})\n",
    "    if label == 'meniscus':\n",
    "        train_meniscus_df = pd.read_csv(f\"{data_dir}/train-{label}.csv\",\n",
    "                                        header=None,\n",
    "                                        names=['Case', 'Meniscus'],\n",
    "                                        dtype={'Case': str, 'Meniscus': np.int64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940e4142",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_abnormal_df['Abnormal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f69219",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_acl_df['ACL'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bfb1af",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_meniscus_df['Meniscus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fedcb15",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.merge(train_abnormal_df, train_acl_df, on='Case').merge(train_meniscus_df, on='Case')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829fa132",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b978165",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5), dpi=80)\n",
    "fig.suptitle('MRNet Train : Total Samples in each Class')\n",
    "\n",
    "# First graph\n",
    "sns.countplot(data = train_df, x='Abnormal', ax=ax[0])\n",
    "ax[0].bar_label(ax[0].containers[0])\n",
    "ax[0].set_xlabel('Abnormal Class')\n",
    "ax[0].set_ylabel('Count of Samples')\n",
    "\n",
    "# Second graph\n",
    "sns.countplot(data = train_df, x='ACL', ax=ax[1])\n",
    "ax[1].bar_label(ax[1].containers[0])\n",
    "ax[1].set_xlabel('ACL Class')\n",
    "ax[1].set_ylabel('Count of Samples')\n",
    "\n",
    "# Third graph\n",
    "sns.countplot(data = train_df, x='Meniscus', ax=ax[2])\n",
    "ax[2].bar_label(ax[2].containers[0])\n",
    "ax[2].set_xlabel('Meniscus Class')\n",
    "ax[2].set_ylabel('Count of Samples')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f597de9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6), dpi=80)\n",
    "ax.pie(x=train_df['ACL'].value_counts(), \n",
    "       labels=train_df['ACL'].value_counts().index,\n",
    "       autopct='%.1f%%')\n",
    "ax.set_title('MRNet Train : Pie Chart of ACL Class Imbalance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadcb6d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# VALID DATASET\n",
    "for label in label_categories:\n",
    "    if label == 'abnormal':\n",
    "        valid_abnormal_df = pd.read_csv(f\"{data_dir}/valid-{label}.csv\",\n",
    "                                        header=None,\n",
    "                                        names=['Case', 'Abnormal'],\n",
    "                                        dtype={'Case': str, 'Abnormal': np.int64})\n",
    "    elif label == 'acl':\n",
    "        valid_acl_df = pd.read_csv(f\"{data_dir}/valid-{label}.csv\",\n",
    "                                   header=None,\n",
    "                                   names=['Case', 'ACL'],\n",
    "                                   dtype={'Case': str, 'ACL': np.int64})\n",
    "    if label == 'meniscus':\n",
    "        valid_meniscus_df = pd.read_csv(f\"{data_dir}/valid-{label}.csv\",\n",
    "                                        header=None,\n",
    "                                        names=['Case', 'Meniscus'],\n",
    "                                        dtype={'Case': str, 'Meniscus': np.int64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7af42c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_abnormal_df['Abnormal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16e4b91",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_acl_df['ACL'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72c198d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_meniscus_df['Meniscus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513cd7c1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_df = pd.merge(valid_abnormal_df, valid_acl_df, on='Case').merge(valid_meniscus_df, on='Case')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834d6328",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8860ff84",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5), dpi=80)\n",
    "fig.suptitle('MRNet Valid : Total Samples in each Class')\n",
    "\n",
    "# First graph\n",
    "sns.countplot(data = valid_df, x='Abnormal', ax=ax[0])\n",
    "ax[0].bar_label(ax[0].containers[0])\n",
    "ax[0].set_xlabel('Abnormal Class')\n",
    "ax[0].set_ylabel('Count of Samples')\n",
    "\n",
    "# Second graph\n",
    "sns.countplot(data = valid_df, x='ACL', ax=ax[1])\n",
    "ax[1].bar_label(ax[1].containers[0])\n",
    "ax[1].set_xlabel('ACL Class')\n",
    "ax[1].set_ylabel('Count of Samples')\n",
    "\n",
    "# Third graph\n",
    "sns.countplot(data = valid_df, x='Meniscus', ax=ax[2])\n",
    "ax[2].bar_label(ax[2].containers[0])\n",
    "ax[2].set_xlabel('Meniscus Class')\n",
    "ax[2].set_ylabel('Count of Samples')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53017f95",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6), dpi=80)\n",
    "ax.pie(x=valid_df['ACL'].value_counts(), \n",
    "       labels=valid_df['ACL'].value_counts().index,\n",
    "       autopct='%.1f%%')\n",
    "ax.set_title('MRNet Valid : Pie Chart of ACL Class Imbalance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00483d31",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e1b171",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Combining both the datasets Train and Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c8b147",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_df = pd.concat([train_df, valid_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6f40d1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5), dpi=80)\n",
    "fig.suptitle('MRNet \\n\\n Total Samples in each Class', fontsize=14)\n",
    "\n",
    "# First graph\n",
    "sns.countplot(data = full_df, x='Abnormal', ax=ax[0])\n",
    "ax[0].bar_label(ax[0].containers[0])\n",
    "ax[0].set_xlabel('Abnormal Class')\n",
    "ax[0].set_ylabel('Count of Samples')\n",
    "\n",
    "# Second graph\n",
    "sns.countplot(data = full_df, x='ACL', ax=ax[1])\n",
    "ax[1].bar_label(ax[1].containers[0])\n",
    "ax[1].set_xlabel('ACL Class')\n",
    "ax[1].set_ylabel('Count of Samples')\n",
    "\n",
    "# Third graph\n",
    "sns.countplot(data = full_df, x='Meniscus', ax=ax[2])\n",
    "ax[2].bar_label(ax[2].containers[0])\n",
    "ax[2].set_xlabel('Meniscus Class')\n",
    "ax[2].set_ylabel('Count of Samples')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0868dfb8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6), dpi=80)\n",
    "fig.suptitle('MRNet', fontsize=14)\n",
    "ax.pie(x=full_df['ACL'].value_counts(), \n",
    "       labels=full_df['ACL'].value_counts().index,\n",
    "       autopct='%.1f%%')\n",
    "ax.set_title('Pie Chart of ACL Class Imbalance', pad=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdbda77",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming you have a Pandas DataFrame called train_df with the columns Abnormal, ACL, Meniscus, etc.\n",
    "\n",
    "# Group by the three columns and calculate the total cases for each combination\n",
    "grouped = train_df.groupby(['Abnormal', 'ACL', 'Meniscus']).size().reset_index(name='Total Cases')\n",
    "\n",
    "# Calculate the total number of cases in the dataset\n",
    "total_cases = grouped['Total Cases'].sum()\n",
    "\n",
    "# Calculate the percentage of total cases for each combination\n",
    "grouped['Percentage'] = np.round((grouped['Total Cases'] / total_cases) * 100, 2)\n",
    "\n",
    "# Display the grouped DataFrame\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bafc3c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_occurence_df = train_df.groupby(['Abnormal', 'ACL', 'Meniscus']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecc4da2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_occurence_df['Percent'] = np.round((train_occurence_df['Case']/train_occurence_df['Case'].sum())*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56abf69c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_occurence_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0355b08b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming you have a Pandas DataFrame called train_df with the columns Abnormal, ACL, Meniscus, etc.\n",
    "\n",
    "# Group by the three columns and calculate the total cases for each combination\n",
    "grouped = valid_df.groupby(['Abnormal', 'ACL', 'Meniscus']).size().reset_index(name='Total Cases')\n",
    "\n",
    "# Calculate the total number of cases in the dataset\n",
    "total_cases = grouped['Total Cases'].sum()\n",
    "\n",
    "# Calculate the percentage of total cases for each combination\n",
    "grouped['Percentage'] = np.round((grouped['Total Cases'] / total_cases) * 100, 2)\n",
    "\n",
    "# Display the grouped DataFrame\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1736da7a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_occurence_df = valid_df.groupby(['Abnormal', 'ACL', 'Meniscus']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccd4eba",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_occurence_df['Percent'] = np.round((valid_occurence_df['Case'] / valid_occurence_df['Case'].sum()) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d9474f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_occurence_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e43864",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Combining both the datasets Train and Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fec602",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming you have a Pandas DataFrame called train_df with the columns Abnormal, ACL, Meniscus, etc.\n",
    "\n",
    "# Group by the three columns and calculate the total cases for each combination\n",
    "grouped = full_df.groupby(['Abnormal', 'ACL', 'Meniscus']).size().reset_index(name='Total Cases')\n",
    "\n",
    "# Calculate the total number of cases in the dataset\n",
    "total_cases = grouped['Total Cases'].sum()\n",
    "\n",
    "# Calculate the percentage of total cases for each combination\n",
    "grouped['Percentage'] = np.round((grouped['Total Cases'] / total_cases) * 100, 2)\n",
    "\n",
    "# Display the grouped DataFrame\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5eff8a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## After Pre-processing and Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495e1ac4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mrnet_dataset_dir = 'Data/MRNet-v1.0'\n",
    "mrnet_train_path = os.path.join(mrnet_dataset_dir, 'train')\n",
    "mrnet_valid_path = os.path.join(mrnet_dataset_dir, 'valid')\n",
    "\n",
    "preprocessed_mrnet_dataset_dir = 'Preprocessed_Data/MRNet-v1.0'\n",
    "preprocessed_mrnet_train_path = os.path.join(preprocessed_mrnet_dataset_dir, 'train')\n",
    "preprocessed_mrnet_valid_path = os.path.join(preprocessed_mrnet_dataset_dir, 'valid')\n",
    "\n",
    "mrnet_planes = ['axial', 'coronal', 'sagittal']\n",
    "\n",
    "# For running code on Windows\n",
    "if platform.system() == \"Windows\":\n",
    "    mrnet_dataset_dir = mrnet_dataset_dir.replace('/', '\\\\')\n",
    "    mrnet_train_path = mrnet_train_path.replace('/', '\\\\')\n",
    "    mrnet_valid_path = mrnet_valid_path.replace('/', '\\\\')\n",
    "    \n",
    "    preprocessed_mrnet_dataset_dir = preprocessed_mrnet_dataset_dir.replace('/', '\\\\')\n",
    "    preprocessed_mrnet_train_path = preprocessed_mrnet_train_path.replace('/', '\\\\')\n",
    "    preprocessed_mrnet_valid_path = preprocessed_mrnet_valid_path.replace('/', '\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726d75ee",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mrnet_datasets = {'train': mrnet_train_path, 'valid': mrnet_valid_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f340d6e6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mrnet_labels = ['abnormal', 'acl', 'meniscus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a0480c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TRAIN DATASET\n",
    "for label in mrnet_labels:\n",
    "    if platform.system() == \"Windows\":\n",
    "        if label == 'abnormal':\n",
    "            train_abnormal_df = pd.read_csv(f\"{mrnet_dataset_dir}\\\\train-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case', 'Abnormal'],\n",
    "                                            dtype={'Case': str, 'Abnormal': np.int64})\n",
    "        elif label == 'acl':\n",
    "            train_acl_df = pd.read_csv(f\"{mrnet_dataset_dir}\\\\train-{label}.csv\",\n",
    "                                       header=None,\n",
    "                                       names=['Case', 'ACL'],\n",
    "                                       dtype={'Case': str, 'ACL': np.int64})\n",
    "        if label == 'meniscus':\n",
    "            train_meniscus_df = pd.read_csv(f\"{mrnet_dataset_dir}\\\\train-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case', 'Meniscus'],\n",
    "                                            dtype={'Case': str, 'Meniscus': np.int64})\n",
    "    else:\n",
    "        if label == 'abnormal':\n",
    "            train_abnormal_df = pd.read_csv(f\"{mrnet_dataset_dir}/train-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case', 'Abnormal'],\n",
    "                                            dtype={'Case': str, 'Abnormal': np.int64})\n",
    "        elif label == 'acl':\n",
    "            train_acl_df = pd.read_csv(f\"{mrnet_dataset_dir}/train-{label}.csv\",\n",
    "                                       header=None,\n",
    "                                       names=['Case', 'ACL'],\n",
    "                                       dtype={'Case': str, 'ACL': np.int64})\n",
    "        if label == 'meniscus':\n",
    "            train_meniscus_df = pd.read_csv(f\"{mrnet_dataset_dir}/train-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case', 'Meniscus'],\n",
    "                                            dtype={'Case': str, 'Meniscus': np.int64})\n",
    "\n",
    "train_df = pd.merge(train_abnormal_df, train_acl_df, on='Case').merge(train_meniscus_df, on='Case')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a2b073",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# VALID DATASET\n",
    "for label in mrnet_labels:\n",
    "    if platform.system() == \"Windows\":\n",
    "        if label == 'abnormal':\n",
    "            valid_abnormal_df = pd.read_csv(f\"{mrnet_dataset_dir}\\\\valid-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case', 'Abnormal'],\n",
    "                                            dtype={'Case': str, 'Abnormal': np.int64})\n",
    "        elif label == 'acl':\n",
    "            valid_acl_df = pd.read_csv(f\"{mrnet_dataset_dir}\\\\valid-{label}.csv\",\n",
    "                                       header=None,\n",
    "                                       names=['Case', 'ACL'],\n",
    "                                       dtype={'Case': str, 'ACL': np.int64})\n",
    "        if label == 'meniscus':\n",
    "            valid_meniscus_df = pd.read_csv(f\"{mrnet_dataset_dir}\\\\valid-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case', 'Meniscus'],\n",
    "                                            dtype={'Case': str, 'Meniscus': np.int64})\n",
    "    else:\n",
    "        if label == 'abnormal':\n",
    "            valid_abnormal_df = pd.read_csv(f\"{mrnet_dataset_dir}/valid-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case', 'Abnormal'],\n",
    "                                            dtype={'Case': str, 'Abnormal': np.int64})\n",
    "        elif label == 'acl':\n",
    "            valid_acl_df = pd.read_csv(f\"{mrnet_dataset_dir}/valid-{label}.csv\",\n",
    "                                       header=None,\n",
    "                                       names=['Case', 'ACL'],\n",
    "                                       dtype={'Case': str, 'ACL': np.int64})\n",
    "        if label == 'meniscus':\n",
    "            valid_meniscus_df = pd.read_csv(f\"{mrnet_dataset_dir}/valid-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case', 'Meniscus'],\n",
    "                                            dtype={'Case': str, 'Meniscus': np.int64})\n",
    "\n",
    "valid_df = pd.merge(valid_abnormal_df, valid_acl_df, on='Case').merge(valid_meniscus_df, on='Case')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c015461c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# AUGMENTED TRAIN LABELS\n",
    "if platform.system() == \"Windows\":\n",
    "    train_aug_df = pd.read_csv(f\"{mrnet_dataset_dir}\\\\train-aug.csv\",\n",
    "                               index_col=0,\n",
    "                               dtype={'Case': str, 'Abnormal': np.int64, 'ACL': np.int64, 'Meniscus': np.int64})\n",
    "else:\n",
    "    train_aug_df = pd.read_csv(f\"{mrnet_dataset_dir}/train-aug.csv\",\n",
    "                               index_col=0,\n",
    "                               dtype={'Case': str, 'Abnormal': np.int64, 'ACL': np.int64, 'Meniscus': np.int64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baeb9d1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# AUGMENTED VALID LABELS\n",
    "if platform.system() == \"Windows\":\n",
    "    valid_aug_df = pd.read_csv(f\"{mrnet_dataset_dir}\\\\valid-aug.csv\",\n",
    "                               index_col=0,\n",
    "                               dtype={'Case': str, 'Abnormal': np.int64, 'ACL': np.int64, 'Meniscus': np.int64})\n",
    "else:\n",
    "    valid_aug_df = pd.read_csv(f\"{mrnet_dataset_dir}/valid-aug.csv\",\n",
    "                               index_col=0,\n",
    "                               dtype={'Case': str, 'Abnormal': np.int64, 'ACL': np.int64, 'Meniscus': np.int64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001d36a7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_mrnet_df = pd.concat([train_df, valid_df, train_aug_df, valid_aug_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16083b87",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(full_mrnet_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0bd6f6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5), dpi=80)\n",
    "fig.suptitle('MRNet \\n\\n Total Samples in each Class', fontsize=14)\n",
    "\n",
    "# First graph\n",
    "sns.countplot(data = full_mrnet_df, x='Abnormal', ax=ax[0])\n",
    "ax[0].bar_label(ax[0].containers[0])\n",
    "ax[0].set_xlabel('Abnormal Class')\n",
    "ax[0].set_ylabel('Count of Samples')\n",
    "\n",
    "# Second graph\n",
    "sns.countplot(data = full_mrnet_df, x='ACL', ax=ax[1])\n",
    "ax[1].bar_label(ax[1].containers[0])\n",
    "ax[1].set_xlabel('ACL Class')\n",
    "ax[1].set_ylabel('Count of Samples')\n",
    "\n",
    "# Third graph\n",
    "sns.countplot(data = full_mrnet_df, x='Meniscus', ax=ax[2])\n",
    "ax[2].bar_label(ax[2].containers[0])\n",
    "ax[2].set_xlabel('Meniscus Class')\n",
    "ax[2].set_ylabel('Count of Samples')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72074a7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6), dpi=80)\n",
    "fig.suptitle('MRNet', fontsize=14)\n",
    "ax.pie(x=full_mrnet_df['ACL'].value_counts(), \n",
    "       labels=full_mrnet_df['ACL'].value_counts().index,\n",
    "       autopct='%.1f%%')\n",
    "ax.set_title('Pie Chart of reduced ACL Class Imbalance', pad=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28a43c0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# **Training Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd717a6d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce37bf3c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331e59b3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548fdd8a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## MRNet Sagittal Plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d39807f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mrnet_dataset_dir = 'Data/MRNet-v1.0'\n",
    "mrnet_train_path = os.path.join(mrnet_dataset_dir, 'train')\n",
    "mrnet_valid_path = os.path.join(mrnet_dataset_dir, 'valid')\n",
    "\n",
    "mrnet_preprocessed_dataset_dir = 'Preprocessed_Data/MRNet-v1.0'\n",
    "mrnet_preprocessed_train_path = os.path.join(mrnet_preprocessed_dataset_dir, 'train')\n",
    "mrnet_preprocessed_valid_path = os.path.join(mrnet_preprocessed_dataset_dir, 'valid')\n",
    "\n",
    "mrnet_planes = ['axial', 'coronal', 'sagittal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742ba112",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For running code on Windows\n",
    "if platform.system() == \"Windows\":\n",
    "    mrnet_dataset_dir = mrnet_dataset_dir.replace('/', '\\\\')\n",
    "    mrnet_train_path = mrnet_train_path.replace('/', '\\\\')\n",
    "    mrnet_valid_path = mrnet_valid_path.replace('/', '\\\\')\n",
    "    \n",
    "    mrnet_preprocessed_dataset_dir = mrnet_preprocessed_dataset_dir.replace('/', '\\\\')\n",
    "    mrnet_preprocessed_train_path = mrnet_preprocessed_train_path.replace('/', '\\\\')\n",
    "    mrnet_preprocessed_valid_path = mrnet_preprocessed_valid_path.replace('/', '\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b923c539",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mrnet_datasets = { 'train' : mrnet_train_path, 'valid' : mrnet_valid_path}\n",
    "mrnet_classes = ['abnormal', 'acl', 'meniscus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a891bdda",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TRAIN DATASET\n",
    "for label in mrnet_classes:\n",
    "    if platform.system() == \"Windows\":\n",
    "        if label == 'abnormal':\n",
    "            train_abnormal_df = pd.read_csv(f\"{mrnet_dataset_dir}\\\\train-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case','Abnormal'],\n",
    "                                            dtype={'Case':str, 'Abnormal':np.int64})\n",
    "        elif label == 'acl':\n",
    "            train_acl_df = pd.read_csv(f\"{mrnet_dataset_dir}\\\\train-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case','ACL'],\n",
    "                                            dtype={'Case':str, 'ACL':np.int64})\n",
    "        if label == 'meniscus':\n",
    "            train_meniscus_df = pd.read_csv(f\"{mrnet_dataset_dir}\\\\train-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case','Meniscus'],\n",
    "                                            dtype={'Case':str, 'Meniscus':np.int64})\n",
    "    else:\n",
    "        if label == 'abnormal':\n",
    "            train_abnormal_df = pd.read_csv(f\"{mrnet_dataset_dir}/train-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case','Abnormal'],\n",
    "                                            dtype={'Case':str, 'Abnormal':np.int64})\n",
    "        elif label == 'acl':\n",
    "            train_acl_df = pd.read_csv(f\"{mrnet_dataset_dir}/train-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case','ACL'],\n",
    "                                            dtype={'Case':str, 'ACL':np.int64})\n",
    "        if label == 'meniscus':\n",
    "            train_meniscus_df = pd.read_csv(f\"{mrnet_dataset_dir}/train-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case','Meniscus'],\n",
    "                                            dtype={'Case':str, 'Meniscus':np.int64})\n",
    "            \n",
    "mrnet_train_df = pd.merge(train_abnormal_df, train_acl_df, on='Case').merge(train_meniscus_df, on='Case')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0341850e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mrnet_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5b0193",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# VALID DATASET\n",
    "for label in mrnet_classes:\n",
    "    if platform.system() == \"Windows\":\n",
    "        if label == 'abnormal':\n",
    "            valid_abnormal_df = pd.read_csv(f\"{mrnet_dataset_dir}\\\\valid-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case','Abnormal'],\n",
    "                                            dtype={'Case':str, 'Abnormal':np.int64})\n",
    "        elif label == 'acl':\n",
    "            valid_acl_df = pd.read_csv(f\"{mrnet_dataset_dir}\\\\valid-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case','ACL'],\n",
    "                                            dtype={'Case':str, 'ACL':np.int64})\n",
    "        if label == 'meniscus':\n",
    "            valid_meniscus_df = pd.read_csv(f\"{mrnet_dataset_dir}\\\\valid-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case','Meniscus'],\n",
    "                                            dtype={'Case':str, 'Meniscus':np.int64})\n",
    "    else:\n",
    "        if label == 'abnormal':\n",
    "            valid_abnormal_df = pd.read_csv(f\"{mrnet_dataset_dir}/valid-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case','Abnormal'],\n",
    "                                            dtype={'Case':str, 'Abnormal':np.int64})\n",
    "        elif label == 'acl':\n",
    "            valid_acl_df = pd.read_csv(f\"{mrnet_dataset_dir}/valid-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case','ACL'],\n",
    "                                            dtype={'Case':str, 'ACL':np.int64})\n",
    "        if label == 'meniscus':\n",
    "            valid_meniscus_df = pd.read_csv(f\"{mrnet_dataset_dir}/valid-{label}.csv\",\n",
    "                                            header=None,\n",
    "                                            names=['Case','Meniscus'],\n",
    "                                            dtype={'Case':str, 'Meniscus':np.int64})\n",
    "\n",
    "mrnet_valid_df = pd.merge(valid_abnormal_df, valid_acl_df, on='Case').merge(valid_meniscus_df, on='Case')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5e005d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mrnet_valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274bbba1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# AUGMENTED TRAIN LABELS\n",
    "if platform.system() == \"Windows\":\n",
    "    mrnet_train_aug_df = pd.read_csv(f\"{mrnet_dataset_dir}\\\\train-aug.csv\",\n",
    "                                     index_col=0,\n",
    "                                     dtype={'Case':str, 'Abnormal':np.int64, 'ACL':np.int64, 'Meniscus':np.int64})\n",
    "else:\n",
    "    mrnet_train_aug_df = pd.read_csv(f\"{mrnet_dataset_dir}/train-aug.csv\",\n",
    "                                     index_col=0,\n",
    "                                     dtype={'Case':str, 'Abnormal':np.int64, 'ACL':np.int64, 'Meniscus':np.int64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab93beb2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mrnet_train_aug_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff7978f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# AUGMENTED VALID LABELS\n",
    "if platform.system() == \"Windows\":\n",
    "    mrnet_valid_aug_df = pd.read_csv(f\"{mrnet_dataset_dir}\\\\valid-aug.csv\",\n",
    "                                     index_col=0,\n",
    "                                     dtype={'Case':str, 'Abnormal':np.int64, 'ACL':np.int64, 'Meniscus':np.int64})\n",
    "else:\n",
    "    mrnet_valid_aug_df = pd.read_csv(f\"{mrnet_dataset_dir}/valid-aug.csv\",\n",
    "                                     index_col=0,\n",
    "                                     dtype={'Case':str, 'Abnormal':np.int64, 'ACL':np.int64, 'Meniscus':np.int64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa2d818",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mrnet_valid_aug_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa85518c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We are working only with Sagittal plane\n",
    "\n",
    "# TRAIN\n",
    "if platform.system() == \"Windows\":\n",
    "    mrnet_sagittal_train_files = glob(mrnet_preprocessed_train_path+\"\\\\sagittal\\\\*.npy\")\n",
    "else:\n",
    "    mrnet_sagittal_train_files = glob(mrnet_preprocessed_train_path+\"/sagittal/*.npy\")\n",
    "mrnet_sagittal_train_files.sort()\n",
    "\n",
    "# VALID\n",
    "if platform.system() == \"Windows\":\n",
    "    mrnet_sagittal_valid_files = glob(mrnet_preprocessed_valid_path+\"\\\\sagittal\\\\*.npy\")\n",
    "else:\n",
    "    mrnet_sagittal_valid_files = glob(mrnet_preprocessed_valid_path+\"/sagittal/*.npy\")\n",
    "mrnet_sagittal_valid_files.sort()\n",
    "\n",
    "# AUGMENTED TRAIN\n",
    "if platform.system() == \"Windows\":\n",
    "    mrnet_sagittal_train_aug_files = glob(mrnet_preprocessed_train_path+\"\\\\sagittal\\\\aug\\\\*.npy\")\n",
    "else:\n",
    "    mrnet_sagittal_train_aug_files = glob(mrnet_preprocessed_train_path+\"/sagittal/aug/*.npy\")\n",
    "mrnet_sagittal_train_aug_files.sort()\n",
    "\n",
    "# AUGMENTED VALID\n",
    "if platform.system() == \"Windows\":\n",
    "    mrnet_sagittal_valid_aug_files = glob(mrnet_preprocessed_valid_path+\"\\\\sagittal\\\\aug\\\\*.npy\")\n",
    "else:\n",
    "    mrnet_sagittal_valid_aug_files = glob(mrnet_preprocessed_valid_path+\"/sagittal/aug/*.npy\")\n",
    "mrnet_sagittal_valid_aug_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dad54e6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(mrnet_sagittal_train_files))\n",
    "print(len(mrnet_sagittal_valid_files))\n",
    "print(len(mrnet_sagittal_train_aug_files))\n",
    "print(len(mrnet_sagittal_valid_aug_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a518997b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mrnet_filenames = []\n",
    "mrnet_filenames.extend(mrnet_sagittal_train_files)\n",
    "mrnet_filenames.extend(mrnet_sagittal_valid_files)\n",
    "mrnet_filenames.extend(mrnet_sagittal_train_aug_files)\n",
    "mrnet_filenames.extend(mrnet_sagittal_valid_aug_files)\n",
    "mrnet_filenames.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd073b7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(mrnet_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99841fbb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(mrnet_train_df)+len(mrnet_valid_df)+len(mrnet_train_aug_df)+len(mrnet_valid_aug_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e393cd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mrnet_full_df = pd.concat([mrnet_train_df, mrnet_valid_df, mrnet_train_aug_df, mrnet_valid_aug_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba8c271",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mrnet_full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38e3105",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_correct_labels_mrnet(filenames, labels_dataframe):\n",
    "    \"\"\"Summary\n",
    "\n",
    "    Args:\n",
    "        filenames (list): List of filenames of the MRI scans\n",
    "        labels_dataframe (pd.Dataframe): Dataframe with all MRNet cases and labels\n",
    "\n",
    "    Returns:\n",
    "        list: List of corresponding labels for given MRNet MRI filenames\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    for file in filenames:\n",
    "        name = os.path.normpath(file).split(os.sep)[-1]\n",
    "        case_name = name.split('.')[0]\n",
    "        label = labels_dataframe.loc[labels_dataframe['Case'] == case_name, 'ACL'].tolist()[0]\n",
    "        labels.append(label)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6849d81",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mrnet_labels = get_correct_labels_mrnet(mrnet_filenames, mrnet_full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be32db8c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mrnet_filenames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6876440f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mrnet_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396deff3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Quick check of counts of samples for each case\n",
    "[[x, mrnet_labels.count(x)] for x in set(mrnet_labels)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41befd5c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Prior to training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85cd5c2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bf5d4a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Splitting into train, test and validation\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(mrnet_filenames, \n",
    "                                        mrnet_labels, \n",
    "                                        test_size=0.1, \n",
    "                                        random_state=610, \n",
    "                                        shuffle=True, \n",
    "                                        stratify=mrnet_labels)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,\n",
    "                                                      y,\n",
    "                                                      train_size=0.7, \n",
    "                                                      random_state=610, \n",
    "                                                      shuffle=True, \n",
    "                                                      stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25cb4f7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "[[x, y_train.count(x)] for x in set(y_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42178895",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "[[x, y_valid.count(x)] for x in set(y_valid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c434ace3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "[[x, y_test.count(x)] for x in set(y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1467b3b9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def compute_class_weights(y_train):\n",
    "    \"\"\"Summary\n",
    "\n",
    "    Args:\n",
    "        y_train (list): List of labels\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary of labels and their corresponding class weights\n",
    "    \"\"\"\n",
    "    class_weights = dict(zip(np.unique(y_train),\n",
    "                             class_weight.compute_class_weight(class_weight='balanced',\n",
    "                                                               classes=np.unique(y_train),\n",
    "                                                               y=y_train)))\n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d9527f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mrnet_class_weights = compute_class_weights(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7525d8b7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mrnet_class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c077505",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## MRNet Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a22326",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = 'MRNet_Model'\n",
    "MRNet_Model3 = models.mri_model_3(model_name, 2)\n",
    "MRNet_Model3.compile(optimizer=keras.optimizers.Adam(learning_rate=utils.model_lr_schedule()),\n",
    "                     loss='binary_crossentropy', \n",
    "                     metrics=['accuracy'])\n",
    "MRNet_Model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e514fc1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def batch_generator(filenames, labels, batch_size):\n",
    "    '''\n",
    "    This function loads the respective filenames and labels in the memory \n",
    "    based on the parameter batch size. It helps to control the amount of\n",
    "    RAM being consumed as the datasets are large.\n",
    "\n",
    "    Args:\n",
    "        filenames (list): List of file paths to the MRI\n",
    "        labels (list): List of corresponding labels of the MRI\n",
    "        batch_size (int): Batch size\n",
    "\n",
    "    Yields:\n",
    "        tuple: Tuple of list of loaded MRI files and corresponding labels\n",
    "    '''\n",
    "    N = len(filenames)\n",
    "    i = 0\n",
    "    random_state_counter = 610\n",
    "    filenames, labels = shuffle(filenames, labels, random_state=random_state_counter + 69)  # Shuffle at the start\n",
    "    while True:\n",
    "        batch_images = []\n",
    "        batch_filenames = filenames[i:i + batch_size]\n",
    "        for file in batch_filenames:\n",
    "            mri_vol = np.load(file)\n",
    "            mri_vol = np.expand_dims(mri_vol, axis=3)  # Adding extra axis for making it compatible for 3D Convolutions\n",
    "            batch_images.append(mri_vol)\n",
    "        batch_labels = labels[i:i + batch_size]\n",
    "        batch_images = np.array(batch_images)\n",
    "        batch_labels = np.array(batch_labels)\n",
    "        yield (batch_images, batch_labels)\n",
    "        i = i + batch_size\n",
    "        if i + batch_size > N:\n",
    "            i = 0\n",
    "            random_state_counter += 1\n",
    "            filenames, labels = shuffle(filenames, labels, random_state=random_state_counter + 69)  # Shuffle at the end of each epoch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416fb3ec",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def model_callback_checkpoint(model_name, model_store_path='Models'):\n",
    "    \"\"\"Summary\n",
    "\n",
    "    Args:\n",
    "        model_name (str): Name of the model\n",
    "        model_store_path (str, optional): Path to store the models\n",
    "\n",
    "    Returns:\n",
    "        TYPE: Keras checkpoint callback to store the best model\n",
    "    \"\"\"\n",
    "    file_name = f\"{model_store_path}/{model_name}/{model_name}.h5\"\n",
    "\n",
    "    # For running code on Windows\n",
    "    if platform.system() == \"Windows\":\n",
    "        file_name = file_name.replace('/', '\\\\')\n",
    "\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(file_name,\n",
    "                                                          save_best_only=True)\n",
    "    return checkpoint_callback\n",
    "\n",
    "\n",
    "def model_callback_earlystopping():\n",
    "    \"\"\"Summary\n",
    "\n",
    "    Returns:\n",
    "        TYPE: Keras earlystopping callback for monitoring Validation Loss\n",
    "    \"\"\"\n",
    "    earlystopping_callback = keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "                                                           patience=10,\n",
    "                                                           verbose=1,\n",
    "                                                           restore_best_weights=True)\n",
    "    return earlystopping_callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b2e052",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with tf.device('/device:GPU:0'):\n",
    "    history = MRNet_Model3.fit(batch_generator(X_train, y_train, BATCH_SIZE),\n",
    "                               steps_per_epoch=len(X_train)//BATCH_SIZE,\n",
    "                               epochs=EPOCHS,\n",
    "                               validation_data=batch_generator(X_valid, y_valid, BATCH_SIZE),\n",
    "                               validation_steps=len(X_valid)//BATCH_SIZE, \n",
    "                               shuffle=True,\n",
    "                               class_weight=mrnet_class_weights,\n",
    "                               verbose=1,\n",
    "                               callbacks=[utils.model_callback_checkpoint(model_name), utils.model_callback_earlystopping()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461f88d9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b74fbb9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdc7357",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ad6103",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 439215,
     "sourceId": 834066,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6.110094,
   "end_time": "2024-08-09T16:21:56.017744",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-09T16:21:49.907650",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
